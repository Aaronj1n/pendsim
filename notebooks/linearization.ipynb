{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rland93/pendsim/blob/master/notebooks/linearization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to True if this is running in a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61m5FYy8PK03"
   },
   "outputs": [],
   "source": [
    "GOOGLE_COLAB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUCHkvy_PK07",
    "outputId": "f6086cfa-ade3-474a-ca98-55ee1d1b8348"
   },
   "outputs": [],
   "source": [
    "if not GOOGLE_COLAB:\n",
    "    %cd ../\n",
    "else:\n",
    "    !pip install git+https://github.com/rland93/pendsim.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JLu3VPgPK0-"
   },
   "outputs": [],
   "source": [
    "from pendsim import sim, controller, viz, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyNids7SPK0_"
   },
   "source": [
    "# Linearization Notebook\n",
    "This notebook explores linearization: what does it mean to linearize a non-linear system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoy1Mw1KPK1A"
   },
   "source": [
    "The inverted pendulum system has an equation of motion:\n",
    "    \n",
    "$$ (M+m)\\ddot{x} - m l \\ddot{\\theta}\\cos{\\theta} + m l \\dot{\\theta} ^2 \\sin{\\theta} = u $$\n",
    "$$ l \\ddot{\\theta} - g \\sin{\\theta} = \\ddot{x} \\cos{\\theta}$$ \n",
    "    \n",
    "This system is a 2nd-order system of differential equations in terms of $x$ and $\\theta$. It is highly non-linear: we have several sines and cosines and some quadratic terms. The system in this form can be very difficult to deal with, especially if we want to do any kind of optimization over it (like in a linear quadratic regulator or model predictive controller). \n",
    "\n",
    "We can easily produce, however, a simplified, linear approximation of the system, that behaves similar to the system in the neighborhood around a given point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePHsVh-mPK1B"
   },
   "source": [
    "To do so, we will use techniques familiar to us from calculus.\n",
    "\n",
    "Let's take a non-linear function, $f(x) = 2 sin(x)$, as an example. This looks squiggly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "46z_5FEEPK1C",
    "outputId": "48cbff09-6584-49c3-dc04-7f060a0f6e67"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,8,500)\n",
    "y = np.sin(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMKdcWoSPK1D"
   },
   "source": [
    "We know from calculus that we can take the derivative of this function and get its Taylor Series around any point $a$ that we want. Let's choose $x=1$.\n",
    "\n",
    "To find the taylor series about $x=a=1$, we evaluate the function's derivative at the point of interest and use that to find the series terms:\n",
    "\n",
    "$$f(a) + \\frac{f'(a)}{1!} (x-a) + \\frac{f''(a)}{2!} (x-a)^2 + \\frac{f'''(a)}{3!} (x-a)^3 ... $$\n",
    "\n",
    "Now, this series continues forever, and it's also non-linear. As we continue to add terms to the summation, the limit approaches our original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxWLjkgHPK1E"
   },
   "outputs": [],
   "source": [
    "# helper function for drawing taylor series\n",
    "def taylor_plot(a, x):\n",
    "    a = 1\n",
    "    y = np.sin(x)\n",
    "    y1 = np.repeat(np.sin(a), y.shape)\n",
    "    y2 = y1 + np.cos(a) * (x-a)\n",
    "    y3 = y2 + np.sin(a) * (1/2.) * (x-a)**2\n",
    "    y4 = y3 + np.cos(a) * (1/6.) * (x-a)**3\n",
    "    y5 = y4 + np.sin(a) * (1/24.) * (x-a)**2\n",
    "    plt.axvline(a, linestyle=\":\", color=\"#555\")\n",
    "    plt.plot(x, y, 'k')\n",
    "    plt.plot(x, y1, color=\"#333\")\n",
    "    plt.plot(x, y2, color=\"#666\")\n",
    "    plt.plot(x, y3, color=\"#888\")\n",
    "    plt.plot(x, y4, color=\"#999\")\n",
    "    plt.plot(x, y4, color=\"#aaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FwXzNzePK1G"
   },
   "source": [
    "We can look at this with our function $y=sin(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "n___Hw0_PK1G",
    "outputId": "69db1a17-f06d-4b91-ee34-187cebcaa950",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,8,500)\n",
    "taylor_plot(1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LAxpA6IPK1H"
   },
   "source": [
    "We can see that our taylor approximations diverge a lot as we get further away from $a$; let's look a little bit closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "z_HOOCPzPK1H",
    "outputId": "a2c97acd-eab8-4e46-ad17-a0f06be464c8"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2, 500)\n",
    "taylor_plot(1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqlyVti5PK1I"
   },
   "source": [
    "So here, we notice a few things. First, that the 0th order taylor approximation isn't giving us much use; it's just the function output at the point $a$. Second, that as we get more terms, we achieve a diminishing return as far as how well the function actually gets approximated. The 2nd, 3rd, 4th order terms are all very close to the 1st order term as far as accuracy, in a region close enough to the pont. So let's look at just the first-order approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "IHtntwg4PK1I",
    "outputId": "1a63fa01-e15f-4f82-a3d3-66814387881c"
   },
   "outputs": [],
   "source": [
    "a = 1\n",
    "# the actual function\n",
    "y = np.sin(x)\n",
    "# 1st order taylor approx.\n",
    "y1 = np.sin(a) + np.cos(a) * (x - a)\n",
    "\n",
    "plt.plot(x, y, 'k')\n",
    "plt.plot(x, y1, '#888')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om4BEp5IPK1J"
   },
   "source": [
    "This is the power of the linear approximation. For a function $f(x)$, if we can find its derivative, we can produce a \"pretty good\" approximation for it around any area we want. Most importantly, that first-order approximation is a *linear* approximation. We notice our `y1` function above:\n",
    "\n",
    "$$ \\sin(a) + \\cos(a) (x-a) $$ \n",
    "\n",
    "Has the same form as the familiar line equation: \n",
    "\n",
    "$$ c_1 + c_2 (x) $$\n",
    "\n",
    "We can extend this line of thinking to the original pendulum system; the linearization method here works for *any* function, no matter how complex, so long as it is differentiable. It's a little bit of effort to take the derivative of the vector-valued system of ODEs we have above, so I'm only going to review it briefly here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo00SI9DPK1J"
   },
   "source": [
    "We represent the pendulum state as a vector: $\\textbf{x} = [x, \\dot{x}, \\theta, \\dot{\\theta}]$. Here, bold $\\textbf{x}$ represents the entire system, not just the cart position. With some rearranging, the original equations of motion can be written in terms of $\\ddot{x}$ and $\\ddot{\\theta}$. The equations of motion can be written in vector form:\n",
    "\n",
    "$$[\\dot{x}, \\ddot{x}, \\dot{\\theta}, \\ddot{\\theta}] = f([x, \\dot{x}, \\theta, \\dot{\\theta}]) $$\n",
    "\n",
    "$$\\dot{\\textbf{x}} = f(\\textbf{x})$$\n",
    "\n",
    "In this form, the derivative of the function $f$ is the jacobian matrix of partial derivatives:\n",
    "\n",
    "$$ \\frac{\\partial \\textbf{x}}{\\partial t} f(\\textbf{x}) $$\n",
    "\n",
    "So that the first-order taylor series approximation of the function is equal to \n",
    "\n",
    "$$ f_{linear}(x) = f(a) + \\frac{\\partial \\textbf{x}}{\\partial t} f(a) (x - a) $$\n",
    "\n",
    "This approximation is often written in the canonical form.\n",
    "\n",
    "$$ \\dot{\\textbf{x}} \\approx A \\textbf{x} + B \\textbf{u} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhj4zeYaPK1K"
   },
   "source": [
    "So, now, we can take steps towards our goal. For a given state $\\textbf{x} = a$, we want to find matrices $A$ and $B$ from this canonical form, by computing the partial derivative $\\frac{\\partial \\textbf{x}}{\\partial t} f(a)$ and rearranging the terms of the first-order taylor series approximation.\n",
    "\n",
    "Which state will we linearize about?\n",
    "\n",
    "In general, we choose the set point of the controller for the linearization. If our controller is any good, it will keep the state within the region surrounding the setpoint, and therefore, if it uses the linearization about that point to do so, it will have an accurate representation of the system state.\n",
    "\n",
    "We choose $\\textbf{a} = [0,0,0,0]$, which corresponds to the upright position.\n",
    "\n",
    "After finding the derivative of our vector-valued function and rearranging some terms, we arrive at the linearized model of our original equation.\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 &-\\frac{m g}{M} & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & \\frac{g m}{l} & 0 \\\\\n",
    "\\end{bmatrix} \\qquad\n",
    "B = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{M} \\\\ \n",
    "0 \\\\\n",
    "- \\frac{1}{l M} \\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1p7VTgsPK1K"
   },
   "source": [
    "So how good is it? In order to see, we can write a simple \"controller\", that just measures parts of the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAxFFZjfPK1K"
   },
   "outputs": [],
   "source": [
    "class Linearization_Measurement(controller.Controller):\n",
    "    def __init__(self, pend, dt) -> None:\n",
    "        self.pend = pend\n",
    "        self.A, self.B = self.get_linear_sys(pend.jacA, pend.jacB, dt)\n",
    "        self.x_1 = np.array([0,0,0.01,0])\n",
    "\n",
    "    def policy(self, state: np.ndarray, dt: float):\n",
    "        # get error from previous state\n",
    "        self.err = state - self.x_1\n",
    "        \n",
    "        \n",
    "        # predict next state\n",
    "        self.x_1 = self.A @ state + self.B @ np.array([0])\n",
    "        action = 0\n",
    "        \n",
    "        # store variables\n",
    "        data = {}\n",
    "        data.update(utils.array_to_kv(\"x_1\", controller.LABELS, self.x_1))\n",
    "        data.update(utils.array_to_kv(\"pred_err\", controller.LABELS, self.err))\n",
    "        return action, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWk13TQPK1L"
   },
   "source": [
    "Now, let's set up a simulation to investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21SK1tIyPK1L",
    "outputId": "5e8e20d1-68e6-496e-a6dc-5cae3a36500d"
   },
   "outputs": [],
   "source": [
    "dt, t_final = 0.01, 10\n",
    "# start slightly tilted so that we get knocked over\n",
    "pend = sim.Pendulum(2, 2, 2, initial_state=np.array([0,0,0.01,0]))\n",
    "cont = Linearization_Measurement(pend, dt)\n",
    "simu = sim.Simulation(dt, t_final, lambda t: 0)\n",
    "results = simu.simulate(pend, cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "1sBGNYisPK1M",
    "outputId": "c1783281-7189-4958-8f21-b94c68e1928e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "ax[0].plot(results[(\"pred_err\", \"t\")].abs())\n",
    "ax[1].plot(results[(\"state\", \"t\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa8iWJDgPK1N"
   },
   "source": [
    "Now we can see pretty clearly that our approximation is good near the linearization point, and decreases as we move away from it. On top, we have the divergence of the linear model from the actual model, and on the bottom, we have the system state. Just like our taylor series for $\\sin(x)$ above -- as we get further away from the linearization point, our 1st-order model becomes less accurate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "linearization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
